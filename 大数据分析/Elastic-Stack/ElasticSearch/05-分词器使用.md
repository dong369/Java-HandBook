# 1 中文分词

中文分词指的是将一个汉字序列切分成一个一个单独的词。在英文中，单词之间是以空格作为自然分界符，汉语中词没有一个飛式上的分界符。上下文不同，分词结果迥异，比如交叉歧义问题，比如下面两种分词都合理。
乒乓球拍/卖/完了
乒乓球/拍卖/院了
https://mp.weixin.qq.com/s/SiHSMrn8lxCmrtHbcwL-NQ

# 1.1 分词系统

### 1.1.1 IK

IK实现中英文单词的切分，支持 ik_smart、 ik_maxword等模式；可自定义词库，支持热更新分词词典。
https://github.com/medcl/elasticsearch-analysis-ik

### 1.1.2 Jieba

Jieba是python中最流行的分词系统，支持分词和词性标注；支持繁体分词、自定义词典、并行分词等
https://github.com/sing1ee/elasticsearch-jieba-plugin

### 1.1.3 Hanlp

基于自然语言处理的分词系统，Hanlp由一系列模型与算法组成的ava工具包，目标是普及自然语言处理在生产环境中的应用https://github.com/hankcs/hanlp

### 1.1.4 THULAC

THULAC是THU Lexical Analyzer for Chinese，由清华大学自然语言处理与社会人文计算实验室硏制推出的一套中文词法分析工具包，具有中文分词和词性标注功能https://github.com/microbun/elasticsearch-thulac-plugin

# 2 IK分词插件

## 1.2.1 安装配置

去<https://github.com/medcl/elasticsearch-analysis-ik/releases>下载对应`Elasticsearch`版本的IK分词插件`elasticsearch-analysis-ik-7.3.0.zip`这个文件。

1、                                                                                                                                                                                                                                                                                    

2、将刚才下载的elasticsearch-analysis-ik7.3.0.zip包解压到该ik目录内

  ```properties
unzip -d elasticsearch-analysis-ik-7.3.0 elasticsearch-analysis-ik-7.3.0.zip
rm -rf elasticsearch-analysis-ik-7.3.0.zip
  ```

## 1.2.2 分词粒度

- ik_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合；
- ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”。

## 1.2.3 分词字典

默认的分词库字典在config下面的文件中。

## 1.2.4 热更新



## 1.2.5 配置field分词

```json
POST /_analyze
{
  "text":"中华人民共和国国徽",
  "analyzer":"ik_max_word"
}

POST /_analyze
{
  "text":"中华人民共和国国徽",
  "analyzer":"ik_smart"
}

PUT /book
{
  "settings": {
    "analysis": {
      "analyzer": {
        "pinyin_analyzer": {
          "tokenizer": "my_pinyin"
        }
      },
      "tokenizer": {
        "my_pinyin": {
          "type": "pinyin",
          "keep_separate_first_letter": false,
          "keep_full_pinyin": true,
          "keep_original": true,
          "limit_first_letter_length": 16,
          "lowercase": true,
          "remove_duplicated_term": true
        }
      }
    }
  }
}
```

# 3 拼音插件

## 2.1 安装Pinyin

去https://github.com/medcl/elasticsearch-analysis-pinyin/releases下载对应Elasticsearch版本的IK分词插件elasticsearch-analysis-pinyin-7.3.0.zip这个文件，打开可以看到如下文件。

```properties
unzip -d elasticsearch-analysis-pinyin-7.3.0 elasticsearch-analysis-pinyin-7.3.0.zip
rm -rf elasticsearch-analysis-pinyin-7.3.0.zip
```

## 2.2 测试使用

```json
DELETE book

PUT /book
{
  "settings": {
    "analysis": {
      "analyzer": {
        "pinyin_analyzer": {
          "tokenizer": "my_pinyin"
        }
      },
      "tokenizer": {
        "my_pinyin": {
          "type": "pinyin",
          "keep_separate_first_letter": false,
          "keep_full_pinyin": true,
          "keep_original": true,
          "limit_first_letter_length": 16,
          "lowercase": true,
          "remove_duplicated_term": true
        }
      }
    }
  }
}


POST /book/_mapping
{
  "properties": {
    "name": {
      "type": "keyword",
      "fields": {
        "pinyin": {
          "type": "text",
          "store": false,
          "term_vector": "with_offsets",
          "analyzer": "pinyin_analyzer",
          "boost": 10
        }
      }
    },
    "content": {
      "type": "text",
      "analyzer": "ik_max_word",
      "search_analyzer": "ik_smart"
    },
    "describe": {
      "type": "text",
      "analyzer": "ik_max_word",
      "search_analyzer": "ik_smart",
      "fields": {
        "pinyin": {
          "type": "text",
          "store": false,
          "term_vector": "with_offsets",
          "analyzer": "pinyin_analyzer",
          "boost": 10
        }
      }
    }
  }
}
```



## 1.2.5 配置field分词

```json
POST /_analyze
{
  "text":"中华人民共和国国徽",
  "analyzer":"pinyin"
}

PUT /book
{
	"settings": {
		"analysis": {
			"analyzer": {
				"pinyin_analyzer": {
					"tokenizer": "my_pinyin"
				}
			},
			"tokenizer": {
				"my_pinyin": {
					"type": "pinyin",
					"keep_separate_first_letter": false,
					"keep_full_pinyin": true,
					"keep_original": true,
					"limit_first_letter_length": 16,
					"lowercase": true,
					"remove_duplicated_term": true
				}
			}
		}
	}
}
```

## 