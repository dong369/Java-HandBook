storm
------------------
	实时计算系统。
	使用场景：实时分析、在线机器学习、持续计算。
	          流计算。
	速度快，每秒每节点处理数据百万tuple级别.
	topology:
	无状态，集群状态和分布式环境信息在zk中保存。
	确保每个消息至少被消费一次。

核心概念
-----------------
	1.tuple				:元组
						 数据结构，有序的元素列表。通常是任意类型的数据，使用，号分割，交给storm计算。
	2.Stream			:一系列tuple。
	3.Spouts			:水龙头。数据源。
	4.Bolts				:转接头。逻辑处理单元，spout数据传给bolt，bolt处理后产生新的数据，可以filter、聚合、分组。
						 接收数据 -> 处理 ->输出给bolt(多个).
	5.Topology			:不会停止的，除非手动杀死。MR是会停止的。
	6.tasks				:spout和bolt的执行过程就是task。
						 spout和bolt都可以以多实例方式运行(在单独的线程中)
	7.workers			:工作节点。storm在worker之间均衡分发任务。监听job，启动或者停止进程。
	8.stream grouping	:控制tuple如何进行路由。
						 内置4个分组策略。

组件
-------------------
	1.Nimubs		:master node,在work node间分发数据，指派task给worker node，监控故障。
	2.Supervisor	:接收nimbus的指令，有多个work进程，监督work进程，完成task。
	3.work prcess	:执行相关的task，本身不执行，创建executor(执行线程),可以有多个执行线程。
	4.executor		:执行线程，由work进程孵化的一个线程，运行一个或多task（有bolt/spout）
	5.task			:处理数据。
	6.zk			:维护状态。


storm架构
----------------------
	1.节点类型
		a)Nimbus	:灵气，master node,
					 主要工作运行topology,分析top，收集执行的task。将task分发给supervisor(可用的)
		b)supervisor:work node.有多个处理进程，代理task给所有的work进程，work进程孵化出足够的线程供task运行。
					 在Nimbus和supervisor之间使用内部的消息系统进行通信。


安装storm
----------------------
	1.jdk
		略 
	2.zk
		略
	3.storm
		a)下载apache-storm-1.0.2.tar.gz
		b)安装
			...
	4.配置storm,不能用tab键。
		[conf/storm.yaml]
		#zk
		storm.zookeeper.servers:
		  - "111.222.333.444"
		  - "555.666.777.888"
		
		#local dir 
		storm.local.dir: "/home/ubuntu/storm"
		
		#nimubs主机配置
		nimbus.seeds: ["111.222.333.44"]
	
		#work进程数(端口数量)
		supervisor.slots.ports:
			- 6700
			- 6701
			- 6702
			- 6703
	
		#storm.health.check.dir: "healthchecks"
		
		#storm.health.check.timeout.ms: 5000
		 
	5.启动storm守护进程
		1.Nimubs
			$>storm nimbus			//启动nimbus
		2.supervisor
			$>storm supervisor
		3.ui
			$>storm ui				//启动web服务器,8080/

storm进程名称
----------------
	1.nimbus
		nimbus
	2.supervisor
		supervisor
	3.core
		ui进程.

编程体验storm
-----------------
	1.创建Spout
		interface IRichSpout
		open()					// 初始化
		nextTuple()				// 通过collector输出数据
		close()					// spout停止时调用的方法
		declareOutputFields()	// 声明tuple输出的schema
		ack()					// 确认特定的tuple被处理
		fail()					// tuple未处理
		
		//创建类
		package com.it18zhang.mystorm102;
	
		import java.util.ArrayList;
		import java.util.List;
		import java.util.Map;
		import java.util.Random;
	
		import org.apache.storm.spout.SpoutOutputCollector;
		import org.apache.storm.task.TopologyContext;
		import org.apache.storm.topology.IRichSpout;
		import org.apache.storm.topology.OutputFieldsDeclarer;
		import org.apache.storm.tuple.Fields;
		import org.apache.storm.tuple.Values;
	
		/**
		 * Spout
		 */
		public class FakeCallLogReaderSpout implements IRichSpout {
			//收集器
			private SpoutOutputCollector collector;
			
			//环境信息
			private TopologyContext context;
			
			//
			private boolean completed = false;


​			
​			//
​			private Random randomGenerator = new Random();
​			
			//
			private Integer idx = 0;
	
			public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
				this.context = context;
				this.collector = collector;
			}
	
			/**
			 * 
			 */
			public void nextTuple() {
				if (this.idx <= 1000) {
					//电话集合
					List<String> mobileNumbers = new ArrayList<String>();
					mobileNumbers.add("1234123401");
					mobileNumbers.add("1234123402");
					mobileNumbers.add("1234123403");
					mobileNumbers.add("1234123404");
					Integer localIdx = 0;
					while (localIdx++ < 100 && this.idx++ < 1000) {
						//主叫
						String fromMobileNumber = mobileNumbers.get(randomGenerator.nextInt(4));
						//被叫
						String toMobileNumber = mobileNumbers.get(randomGenerator.nextInt(4));
						
						while (fromMobileNumber == toMobileNumber) {
							toMobileNumber = mobileNumbers.get(randomGenerator.nextInt(4));
						}
						//生成随机数,表示通话时长
						Integer duration = randomGenerator.nextInt(60);
						
						//输出通话记录
						this.collector.emit(new Values(fromMobileNumber, toMobileNumber, duration));
					}
				}
			}
	
			public void declareOutputFields(OutputFieldsDeclarer declarer) {
				declarer.declare(new Fields("from", "to", "duration"));
			}
	
			public void close() {
			}
	
			public boolean isDistributed() {
				return false;
			}
	
			public void activate() {
			}
	
			public void deactivate() {
			}
	
			public void ack(Object msgId) {
			}
	
			public void fail(Object msgId) {
			}
	
			public Map<String, Object> getComponentConfiguration() {
				return null;
			}
		}
	2.创建CallLogCreatorBolt
		package com.it18zhang.mystorm102;
	
		import java.util.Map;
	
		import org.apache.storm.task.OutputCollector;
		import org.apache.storm.task.TopologyContext;
		import org.apache.storm.topology.IRichBolt;
		import org.apache.storm.topology.OutputFieldsDeclarer;
		import org.apache.storm.tuple.Fields;
		import org.apache.storm.tuple.Tuple;
		import org.apache.storm.tuple.Values;
	
		/**
		 * Bolt
		 */
		public class CallLogCreatorBolt implements IRichBolt {
			//
			private OutputCollector collector;
	
			//initialize
			public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
				this.collector = collector;
			}
	
			public void execute(Tuple tuple) {
				//主叫
				String from = tuple.getString(0);
				//被叫
				String to = tuple.getString(1);
				//通话时长
				Integer duration = tuple.getInteger(2);
				//
				collector.emit(new Values(from + " - " + to, duration));
			}
	
			/**
			 * 
			 */
			public void cleanup() {
			}
	
			public void declareOutputFields(OutputFieldsDeclarer declarer) {
				declarer.declare(new Fields("call", "duration"));
			}
	
			public Map<String, Object> getComponentConfiguration() {
				return null;
	
			}
		}
	
	3.CallLogCounterBolt
		package com.it18zhang.mystorm102;
	
		import java.util.HashMap;
		import java.util.Map;
	
		import org.apache.storm.task.OutputCollector;
		import org.apache.storm.task.TopologyContext;
		import org.apache.storm.topology.IRichBolt;
		import org.apache.storm.topology.OutputFieldsDeclarer;
		import org.apache.storm.tuple.Fields;
		import org.apache.storm.tuple.Tuple;
	
		/**
		 * Bolt
		 */
		public class CallLogCounterBolt implements IRichBolt {
			//
			Map<String, Integer> counterMap;
			//
			private OutputCollector collector;
	
			public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
				this.counterMap = new HashMap<String, Integer>();
				this.collector = collector;
			}
	
			public void execute(Tuple tuple) {
				//call
				String call = tuple.getString(0);
				//duration
				Integer duration = tuple.getInteger(1);
				
				if (!counterMap.containsKey(call)) {
					counterMap.put(call, 1);
				} else {
					Integer c = counterMap.get(call) + 1;
					counterMap.put(call, c);
				}
				collector.ack(tuple);
			}
	
			public void cleanup() {
				for (Map.Entry<String, Integer> entry : counterMap.entrySet()) {
					System.out.println(entry.getKey() + " : " + entry.getValue());
				}
			}
	
			public void declareOutputFields(OutputFieldsDeclarer declarer) {
				declarer.declare(new Fields("call"));
			}
	
			public Map<String, Object> getComponentConfiguration() {
				return null;
			}
		}
	4.创建Topology
		package com.it18zhang.mystorm102;
	
		import org.apache.storm.Config;
		import org.apache.storm.LocalCluster;
		import org.apache.storm.topology.TopologyBuilder;
		import org.apache.storm.tuple.Fields;
	
		/**
		 *
		 */
		public class App {
			public static void main(String[] args) throws Exception {
				
				Config config = new Config();
				config.setDebug(true);
				//builder
				TopologyBuilder builder = new TopologyBuilder();
				//设置spout
				builder.setSpout("call-log-reader-spout", new FakeCallLogReaderSpout());
				
				//设置bolt
				builder.setBolt("call-log-creator-bolt", new CallLogCreatorBolt()).shuffleGrouping("call-log-reader-spout");
				
				//设置bolt,设置分组策略
				builder.setBolt("call-log-counter-bolt", new CallLogCounterBolt()).fieldsGrouping("call-log-creator-bolt",
						new Fields("call"));
				
				//本地集群模式
				LocalCluster cluster = new LocalCluster();
				
				//向集群中提交top
				cluster.submitTopology("LogAnalyserStorm", config, builder.createTopology());
				Thread.sleep(10000);
				cluster.shutdown();
			}
		}
	
	5.直接运行main().
	6.在完全分布式集群上运行
		1.删除LocalCluster,使用StormSubmitter.submitTopology("StormApp", config, builder.createTopology());
	
		2.导出jar
			...
		3.提交到storm集群运行
			$>storm jar xxx.jar com.it18zhang.mystorm102.App