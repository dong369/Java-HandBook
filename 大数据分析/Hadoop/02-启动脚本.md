# 1 基础知识

1.1 配置模式
-------------------

	1.standalone/local
		独立/本地模式.
		不需要启用守护进程。
		所有的程序都运行一个JVM中。
		默认模式。
		nothing！！!
	2.pseudo
		伪分布式.
		需要启动守护进程(start-all.sh)。(NN,DN,2NN,RM,NM)
		只有一个台主机。
		[配置]
		core-site.xml
		fs.defaultFS=hdfs://localhost:8020/
	
		hdfs-site.xml
		dfs.replication=1
	
		mapred-site.xml
		mapreduce.framework.name=yarn
	
		yarn-site.xml
		yarn.resourcemanager.hostname=localhost
	
		slaves
		localhost
	
	3.full distributed
		完全分布式。
		类似于伪分布式。
		[配置]
		core-site.xml
		fs.defaultFS=hdfs://s100:8020/
	
		hdfs-site.xml
		dfs.replication=3
	
		mapred-site.xml
		mapreduce.framework.name=yarn
	
		yarn-site.xml
		yarn.resourcemanager.hostname=s100
	
		// 配置数据节点，3.2.1版本后将slaves改为了works
		[slaves]
		s101
		s102
		s103


1.2 SSH
---------------
	安全无密码登录


1.3 模块构成
---------------
	1.common
	2.hdfs
		start-dfs.sh/stop-dfs.sh
		nn
		dn
		2nn
	3.yarn
		start-yarn.sh/stop-dfs.sh
		rm
		nm
	4.mapred

## 1.4 帮助查看

```properties
# hadoop --help
# hdfs --help
# hdfs dfs --help
# hdfs dfs -help rm
```

# 2 Hadoop脚本

2.1 脚本分析
-------------------

	1、start-all.sh
		libexec/hadoop-config.sh						--设置变量
		sbin/start-dfs.sh --config $HADOOP_CONF_DIR		--启动hdfs
		sbin/start-yarn.sh --config $HADOOP_CONF_DIR	--启动yarn
	
	2、libexec/hadoop-config.sh							--设置变量（很多地方都用到）
		COMMON_DIR
		...
		HADOOP_CONF_DIR=...
		HEAP_SIZE=1000m,
		CLASSPATH=...
	
	3、sbin/start-dfs.sh --config $HADOOP_CONF_DIR		--启动hdfs
		1.libexec/hdfs-config.sh						--等价于hadoop-config.sh		
		 
		2.#获得名称节点主机名
		  NAMENODES = hdfs getconf -namenodes
	
		3.启动名称节点
			"$HADOOP_PREFIX/sbin/hadoop-daemons.sh" \
			  --config "$HADOOP_CONF_DIR" \
			  --hostnames "$NAMENODES" \
			  --script "$bin/hdfs" start namenode $nameStartOpt
		
		4.启动datanode
		"$HADOOP_PREFIX/sbin/hadoop-daemons.sh" \
			--config "$HADOOP_CONF_DIR" \
			--script "$bin/hdfs" start datanode $dataStartOpt
		
		5.启动2nn
		"$HADOOP_PREFIX/sbin/hadoop-daemons.sh" \
			  --config "$HADOOP_CONF_DIR" \
			  --hostnames "$SECONDARY_NAMENODES" \
			  --script "$bin/hdfs" start secondarynamenode
	
	4、libexec/hdfs-config.sh
		libexec/hadoop-config.sh
	
	5、sbin/hadoop-daemons.sh			--启动守护进程脚本
		1.libexec/hdfs-config.sh		--执行配置脚本
		2.slaves.sh" --config $HADOOP_CONF_DIR cd "$HADOOP_PREFIX" \; 
							"$bin/hadoop-daemon.sh" --config $HADOOP_CONF_DIR "$@"
			
			循环slaves文件,通过ssh方式登录远程主机，执行相应命令
			
			[bin/hadoop-daemon.sh]
				hadoop-config.sh
				[bin/hdfs]
				
		3.daemons和daemon的区别？
			daemons是启动多个进行，daemon是启动单个守护进程，在本机进行操作的
			hadoop-daemon.sh start namenode
			hadoop-daemon.sh start secondarynamenode
			hadoop-daemons.sh start datanode
			
			hdfs --daemon start namenode
			hdfs --daemon stop namenode
	6、bin/hadoop
		hadoop-config.sh
		java程序 ....
	7、bin/hdfs
		hadoop-config.sh
		java程序

ACID特性

a、atomic			// 原子性
c、conssitent		// 一致性
i、isolation			// 隔离性
d、durable			// 永久性

2.2 常用命令
-------------
	1、格式化系统
		hadoop namenode -format
	2、put === copyFormLocal上传文件
		hadoop fs -put // hdfs dsf -put
		hdfs dfs -put  // 等价关系
	3、重命名
		hdfs dfs -mv ./sshd.txt ./how.txt
	4、下载
		hdfs dfs -get ./ssh.txt ./kk.txt
		hdfs dfs -copyToLocal 
	5、移动到hdfs
		hdfs dfs -moveFromLocal hello.txt .
	6、从hdfs移动到本地，没有实现。
		// 
	7、删除文件(也可以删除目录)
		hdfs dfs -rm -r --
	8、删除目录(空目录)
		hdfs dfs -rmdir ...
	9、在hdfs上进行文件复制
		hdfs dfs -cp /user/ubuntu/hello.txt /user/hello2.txt
	10、文件列表查看
		hdfs dfs -ls -R /

2.3 扩展配置信息
--------------------
	1.namenode的本地目录配置成多个,则每个目录存放内容相同,可靠性。
		[hdfs-site.xml]
		dfs.namenode.name.dir=file:///${hadoop.tmp.dir}/dfs/name1,file:///${hadoop.tmp.dir}/dfs/name2
	
	2.datanode也可以配置多个目录,不是副本。
		[hdfs-site.xml]
		dfs.datanode.data.dir=file:///${hadoop.tmp.dir}/dfs/data1,file:///${hadoop.tmp.dir}/dfs/data2

2.4 Hdfs文件块
----------------------------

hadoop hdfs文件块大小(128M)

	磁盘寻道时间。
	磁盘的寻道时间==10ms
	磁盘的IO速率:100MB/s
	
	10 * 100 = 1s * 100M/s = 100M

## 2.5 配置属性

查询集群的配置属性

	$>hdfs getconf 

## 2.6 API访问

通过API访问hdfs

	1.eclipse
