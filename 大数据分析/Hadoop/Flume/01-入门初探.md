1 Flume
=============

Flume是由 Cloudera提供的一个分布式、高可靠、高可用的服务，用于分布式的海量日志的高效收集、聚合、移动系统

	Flume是由Cloudera公司提供的一个是分布式、可靠、可用性好服务，用于收集、聚合、移动大量日志数据。
	基于流计算的简单灵活架构。用于在线分析。通过agent配置文件。

设计目标：可靠性、扩展性、管理性。

1.1 stream
------------

	动态计算。


1.2 优点
--------------
	1.可以和任意集中式存储进程集成。
	2.输入的数据速率大于写入存储目的地的速度，flume会进行缓冲。
	3.flume提供上下文路由.(数据流路线)
	4.flume中的事务基于channe，使用了两个事务模型（sender + receiver）
	  确保消息被可靠发送
	5.Flume is reliable, fault tolerant, scalable, manageable, and customizable.

1.3 特点
----------------
	1.flume高效收集web server的log到hdfs。
	2.可以高效获取输入。
	3.导入大量数据
	4.flume支持大量的source和destination类型
	5.flume支持多级跳跃、source和destiination的fan in和fan out .
	6.flume可以水平伸缩。


1.4 put的问题
-------------------
	1.同一时刻只能传输一个文件.
	2.put处理的静态文件。

1.5 架构
--------------------
	1.描述
		在数据生成器运行的节点上启动单独的flume agent，来收集数据。
		数据收集器收集数据，推送到hdfs。
	2.Fluem Event
		事件是flume的传输单元。主要是byte[],可以含有一些header信息。
		在source和destination之间。
	3.Flume agent
		每个agent是一个独立的java进程，从客户端(其他agent)接收数据，
		然后转发到下一个destination(sink | agent)
		agent包含三个组件:
		a.source
		  [源头]
		  从事件生成器接收数据，以event事件的形式传给一个或多个channel。
		b.channel
		  [通道]
		  从source中接收flume event，做为临时存放地，缓存到buffer中，直到
		  sink将其消费掉。是source和sink之间的桥梁.
		  channel是事务的，可以和多个source或sink协同。
		c.sink
		  [沉槽]
		  存放数据到hdfs，从channel中消费event，并分发给destination,sink的
		  destination也可以是另一个agent或者hdfs。
	
		 注意:一个flume的agent，可以有多个source、channel、sink.

1.6 附加组件
--------------
	1.Interceptors // 收集
	2.Channel Selectors // 聚集
	3.Sink Processors // 输出

## 1.7 同类产品

flume、scribe（不维护）、chukwa（不维护）、kafka、fluentd、logstash、sqoop

# 2 安装配置

2.1 安装flume
-----------------

	1.下载flume基础环境
		jdk、内存、磁盘、权限
	2.进行解压apache-flume-1.9.0-bin.tar.gz
	3.配置环境变量
		[etc/environment]
		FLUME_HOME
		PATH=...:
	4.验证安装
		$>flume-ng version
	5.配置flume
		[flume/conf/flume]

2.2 配置flume
---------------------
	1.命名agent组件
	2.描述配置source
	3.描述配置channel
	4.描述配置sink
	5.绑定source，sink到channel
	
	a1.sources=r1,r2
	a1.sinks=s1,s2
	a1.channels=c1,c2
	
	#source-r1
	a1.sources.r1.type=
	a1.sources.r1.xxx=
	a1.sources.r1.yyy=
	
	#sink-s1
	a1.sinks.s1.type=
	a1.sinks.s1.xxx=
	
	#channel-c1
	a1.channels.c1.type=
	a1.channels.c1.xxx=
	
	#binding,source可以配置多个channel
	a1.sources.r1.channels=c1
	
	#sink只能配置一个channel
	a1.sinks.s1.channel=c1

Simple案例

2.3 使用flume
-------------------
	1.配置conf/flume.properties
		a1.sources = r1
		a1.sinks = k1
		a1.channels = c1
	
		# Describe/configure the source
		a1.sources.r1.type = netcat
		a1.sources.r1.bind = localhost
		a1.sources.r1.port = 44444
	
		# Describe the sink
		a1.sinks.k1.type = logger
	
		# Use a channel which buffers events in memory
		a1.channels.c1.type = memory
		a1.channels.c1.capacity = 1000
		a1.channels.c1.transactionCapacity = 100
	
		# Bind the source and sink to the channel
		a1.sources.r1.channels = c1
		a1.sinks.k1.channel = c1
	
	2.运行flume agent
		#--conf		: 配置目录
		#--conf-file: 配置文件
		#--name		: 代理名称
		#-D			: 指定额外的参数
		$>cd flume/conf
		$>flume-ng agent --conf . 
						--conf-file flume-conf.properties --name a1 -Dflume.root.logger=INFO,console

2.4 核心类考查
------------------
	1.Source
		生成Event，调用ChannelProcessor的方法，将Event
		put到Channel中去.
		Source --> Event -->ChannelProcessor ->InterceptorChain(e) --> Channels(e);
	
		start()
		stop();


	2.Sink
		连接到Channel，消费里面的Event,将其发送到destination,有很多相应的sink类型
		Sink可以根据SinkGroup和SinkProcessor进行分组，通过Processor由SinkRunner轮询出来。
		Sink的process()方法只能由一个线程访问。
		setChannel()
		getChannel()
		process();


	3.Channel
		连接Source(Event Procuder)和Sink(Event Consumer),本质上Channel就是Buffer.
		支持事务处理,保证原子性(put + take)
		Channel是线程安全的。
		put()
		take();
		getTransaction();
	4.flume的入口点org.apache.flume.node.Application

# 3 数据源

3.1 使用avro源
------------------

	1、配置
	[avro-r.properties]
	a1.sources = r1
	a1.channels = c1
	a1.sinks=s1
	
	#source
	a1.sources.r1.type = avro
	a1.sources.r1.bind = 0.0.0.0
	a1.sources.r1.port = 4141
	
	#sink
	a1.sinks.s1.type=logger
	
	#channel
	a1.channels.c1.type=memory
	
	#bind
	a1.sources.r1.channels = c1
	a1.sinks.s1.channel=c1
	
	2.启动
		$>flume-ng agent --conf . --conf-file avor-r -n a1 -Dflume.root.logger=INFO,console
	3.通过flume-ng avro-cliet命令发送avro数据消息
		$>flume-ng avro-client -H localhost -p 8888 helloworld

## 3.2 ZK中读取

flume配置文件存放进zk中，从zk进行配置读取

	1.通过程序将数据写入zk中指定的节点
		String conn = "s101:2181,s102:2181,s103:2181" ;
		ZooKeeper zk = new ZooKeeper(conn, 50000, new Watcher(){
			public void process(WatchedEvent event) {
				System.out.println("over : " + event);
			}
		});
		
		Stat s = new Stat() ;
		zk.getData("/flume/a1", false, s);
		int v = s.getVersion();
		FileInputStream fis = new FileInputStream("d:/avro-r.conf");
		byte[] data = new byte[fis.available()];
		fis.read(data);
		fis.close();
		zk.setData("/flume/a1", data, v);
	2.在flume-ng中通过--z指定节点位置，提取属性
		flume-ng agent --conf . --conf-file xxx -z s101:2181,s102:2181 -p /flume --name a1 -Dflume.root.logger=INFO,console

## 3.3 Oracle源

1、上传jar包到lib（ojdbc6.jar、flume-ng-sql-source-1.4.1.jar）

2、创建配置文件sql-kafka.conf

```properties
# name
agent.sources = sql-source
agent.channels = ch1
agent.sinks = kafka-sink

# source
agent.sources.sql-source.type = org.keedio.flume.source.SQLSource
agent.sources.sql-source.hibernate.connection.url = jdbc:oracle:thin:@192.168.10.56:1521/xe
agent.sources.sql-source.hibernate.connection.user = system
agent.sources.sql-source.hibernate.connection.password = oracle
agent.sources.sql-source.hibernate.connection.autocommit = true
agent.sources.sql-source.status.file.path = /home/guodd/flume
agent.sources.sql-source.status.file.name = agent.sqlSource.status

# 增量数据配置
agent.sources.sql-source.table = goods
agent.sources.sql-source.columns.to.select = *  
agent.sources.sql-source.incremental.column.name = id  
agent.sources.sql-source.incremental.value = 0
agent.sources.sql-source.run.query.delay = 5000

# channel
agent.channels.ch1.type = memory

# sink
agent.sinks.kafka-sink.type = org.apache.flume.sink.kafka.KafkaSink
agent.sinks.kafka-sink.topic = test
agent.sinks.kafka-sink.brokerList = 192.168.10.10:9092
agent.sinks.kafka-sink.requiredAcks = 1  
agent.sinks.kafka-sink.batchSize = 20 

agent.sources.sql-source.channels = ch1
agent.sinks.kafka-sink.channel = ch1
```

3、进行启动

flume-ng agent --name agent --conf conf/ --conf-file conf/oracle-agent.conf -Dflume.root.logger=INFO,console

## 3.4 MySQL源

```properties
# name
agent.sources = sql-source
agent.channels = ch1
agent.sinks = kafka-sink

# source
agent.sources.sql-source.type = org.keedio.flume.source.SQLSource
agent.sources.sql-source.hibernate.connection.url = jdbc:mysql://192.168.2.110:3306/test
agent.sources.sql-source.hibernate.connection.user = root
agent.sources.sql-source.hibernate.connection.password = passw0rd
agent.sources.sql-source.hibernate.connection.autocommit = true
agent.sources.sql-source.status.file.path = /home/guodd/flume
agent.sources.sql-source.status.file.name = agent.sqlSource.status

# 增量数据配置
agent.sources.sql-source.table = goods
agent.sources.sql-source.columns.to.select = *  
agent.sources.sql-source.incremental.column.name = id  
agent.sources.sql-source.incremental.value = 0
agent.sources.sql-source.run.query.delay = 5000

# channel
agent.channels.ch1.type = memory

# sink
agent.sinks.kafka-sink.type = org.apache.flume.sink.kafka.KafkaSink
agent.sinks.kafka-sink.topic = test
agent.sinks.kafka-sink.brokerList = 192.168.10.10:9092
agent.sinks.kafka-sink.requiredAcks = 1  
agent.sinks.kafka-sink.batchSize = 20 

agent.sources.sql-source.channels = ch1
agent.sinks.kafka-sink.channel = ch1
```

flume-ng agent --name agent --conf conf/ --conf-file conf/mysql-agent.conf -Dflume.root.logger=INFO,console

3.5 使用exec源
-----------

	 略


3.6 使用spooldir source
--------------------
	a1.sources.r1.type = spooldir
	a1.sources.r1.spoolDir=/home/ubuntu/a


3.7 SequenceGeneratorSource
-----------------------
	a1.sources = r1
	a1.sources.r1.type = seq


3.8 TcpSysLog
------------------------------
a1.sources.r1.type = syslogtcp
a1.sources.r1.port = 8888
a1.sources.r1.host = localhost

3.9 source-syslogudp
-----------------
a1.sources = r1
a1.sources.r1.type = syslogudp
a1.sources.r1.port = 5140
a1.sources.r1.host = localhost


3.10 http source
-----------------
	走http协议,默认使用json格式处理器
	a1.sources.r1.type = http
	a1.sources.r1.port = 5140

3.11 Stress source
------------------
	a1.sources.r1.type = org.apache.flume.source.StressSource
	a1.sources.r1.size = 10240
	a1.sources.r1.maxTotalEvents = 1000000


3.12 FQCN 
 ------------
	full qualifier component name，完整限定组件名.


3.13 自定义Source
--------------------
	1.自定义类
		/**
		 * 自定义Source
		 */
		public class MySource extends AbstractSource {
	
			public synchronized void start() {
				super.start();
				ChannelProcessor cp = this.getChannelProcessor();
				Map<String, String> map = new HashMap<String, String>();
				map.put("owner", "xupc");
				map.put("date", "2016/09/29");
				Event e  = null ;
				for(int i = 0 ; i < 100000 ; i++){
					e = new SimpleEvent();
					e.setBody(("tom" + i).getBytes());
					e.setHeaders(map);
				}
				cp.processEvent(e);
			}
		}
	2.导出jar
	3.复制到flume/lib/下
	4.创建custom-r.conf
		a1.sources.r1.type = com.it18zhang.myflume160.source.MySource
	
	5.