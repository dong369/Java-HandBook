

**Apache Spark**是一个[开源](https://zh.wikipedia.org/wiki/开源)集群**运算框架**，最初是由加州大学柏克莱分校AMPLab所开发。相对于[Hadoop](https://zh.wikipedia.org/wiki/Apache_Hadoop)的[MapReduce](https://zh.wikipedia.org/wiki/MapReduce)会在运行完工作后将中介数据存放到磁盘中，Spark使用了存储器内运算技术，能在数据尚未写入硬盘时即在存储器内分析运算。Spark在存储器内运行程序的运算速度能做到比Hadoop MapReduce的运算速度快上100倍，即便是运行程序于硬盘时，Spark也能快上10倍速度。[[1\]](https://zh.wikipedia.org/wiki/Apache_Spark#cite_note-1)Spark允许用户将数据加载至集群存储器，并多次对其进行查询，非常适合用于[机器学习](https://zh.wikipedia.org/wiki/机器学习)算法。